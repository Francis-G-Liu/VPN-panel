"""
AI æ™ºèƒ½è°ƒåº¦æœåŠ¡

è´Ÿè´£å®šæœŸè®¡ç®—èŠ‚ç‚¹çš„ AI è¯„åˆ†ï¼Œç”¨äºæ™ºèƒ½æ¨èæœ€ä¼˜èŠ‚ç‚¹ã€‚

è¯„åˆ†é€»è¾‘ï¼š
- å»¶è¿Ÿå¾—åˆ† (40%): å»¶è¿Ÿè¶Šä½åˆ†è¶Šé«˜
- è´Ÿè½½å¾—åˆ† (30%): CPU/è´Ÿè½½è¶Šä½åˆ†è¶Šé«˜  
- ç¨³å®šæ€§å¾—åˆ† (30%): ä¸¢åŒ…ç‡è¶Šä½åˆ†è¶Šé«˜
- æ™šé«˜å³°æƒ©ç½š: æ‹¥å µæ—¶æ®µæ‰£å‡ 20 åˆ†

ä½œè€…: AI VPN Team
æ—¥æœŸ: 2026-02-05
"""

import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from statistics import mean

from sqlmodel import Session, select
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger

from backend.database import get_session
from backend.models import Node, NodeMetrics


logger = logging.getLogger(__name__)


class AISchedulerService:
    """
    AI æ™ºèƒ½è°ƒåº¦æœåŠ¡
    
    è´Ÿè´£å®šæœŸè®¡ç®—å’Œæ›´æ–°èŠ‚ç‚¹çš„ AI è¯„åˆ†
    """
    
    def __init__(self, interval_seconds: int = 60):
        """
        åˆå§‹åŒ–è°ƒåº¦æœåŠ¡
        
        Args:
            interval_seconds: è°ƒåº¦é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 60 ç§’
        """
        self.interval_seconds = interval_seconds
        self.scheduler = AsyncIOScheduler()
        
    def start(self):
        """å¯åŠ¨å®šæ—¶è°ƒåº¦"""
        logger.info("ğŸ¤– å¯åŠ¨ AI è°ƒåº¦æœåŠ¡...")
        
        # æ·»åŠ å®šæ—¶ä»»åŠ¡
        self.scheduler.add_job(
            self.update_all_nodes_scores,
            trigger=IntervalTrigger(seconds=self.interval_seconds),
            id='update_node_scores',
            name='æ›´æ–°èŠ‚ç‚¹ AI è¯„åˆ†',
            replace_existing=True
        )
        
        # å¯åŠ¨è°ƒåº¦å™¨
        self.scheduler.start()
        logger.info(f"âœ… AI è°ƒåº¦æœåŠ¡å·²å¯åŠ¨ï¼Œæ¯ {self.interval_seconds} ç§’æ›´æ–°ä¸€æ¬¡")
        
        # ç«‹å³æ‰§è¡Œä¸€æ¬¡
        self.update_all_nodes_scores()
    
    def stop(self):
        """åœæ­¢è°ƒåº¦æœåŠ¡"""
        logger.info("ğŸ›‘ åœæ­¢ AI è°ƒåº¦æœåŠ¡...")
        self.scheduler.shutdown()
        logger.info("âœ… AI è°ƒåº¦æœåŠ¡å·²åœæ­¢")
    
    def update_all_nodes_scores(self):
        """
        æ›´æ–°æ‰€æœ‰èŠ‚ç‚¹çš„ AI è¯„åˆ†
        
        è¿™æ˜¯å®šæ—¶ä»»åŠ¡çš„ä¸»è¦æ‰§è¡Œå‡½æ•°
        """
        logger.info("=" * 60)
        logger.info("ğŸ“Š å¼€å§‹æ›´æ–°èŠ‚ç‚¹ AI è¯„åˆ†...")
        
        with next(get_session()) as session:
            # è·å–æ‰€æœ‰æ´»è·ƒèŠ‚ç‚¹
            statement = select(Node).where(Node.is_active == True)
            nodes = session.exec(statement).all()
            
            if not nodes:
                logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ´»è·ƒèŠ‚ç‚¹")
                return
            
            logger.info(f"ğŸ“Œ æ‰¾åˆ° {len(nodes)} ä¸ªæ´»è·ƒèŠ‚ç‚¹")
            
            # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„è¯„åˆ†
            updated_count = 0
            for node in nodes:
                try:
                    # è·å–èŠ‚ç‚¹çš„ç›‘æ§æ•°æ®
                    metrics = self.get_recent_metrics(session, node.id)
                    
                    if not metrics:
                        logger.warning(f"âš ï¸  èŠ‚ç‚¹ {node.name} (ID:{node.id}) æ²¡æœ‰ç›‘æ§æ•°æ®")
                        continue
                    
                    # è®¡ç®— AI è¯„åˆ†
                    score = self.calculate_node_score(node, metrics)
                    
                    # æ›´æ–°æ•°æ®åº“
                    node.ai_score = score
                    session.add(node)
                    
                    logger.info(f"  âœ… {node.name}: {score:.2f}/100")
                    updated_count += 1
                
                except Exception as e:
                    logger.error(f"âŒ æ›´æ–°èŠ‚ç‚¹ {node.name} å¤±è´¥: {e}")
            
            # æäº¤äº‹åŠ¡
            session.commit()
            
            logger.info(f"âœ… æˆåŠŸæ›´æ–° {updated_count}/{len(nodes)} ä¸ªèŠ‚ç‚¹çš„è¯„åˆ†")
            logger.info("=" * 60)
    
    def get_recent_metrics(
        self,
        session: Session,
        node_id: int,
        minutes: int = 5
    ) -> List[NodeMetrics]:
        """
        è·å–èŠ‚ç‚¹æœ€è¿‘çš„ç›‘æ§æ•°æ®
        
        Args:
            session: æ•°æ®åº“ä¼šè¯
            node_id: èŠ‚ç‚¹ ID
            minutes: æ—¶é—´èŒƒå›´ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤ 5 åˆ†é’Ÿ
        
        Returns:
            ç›‘æ§è®°å½•åˆ—è¡¨
        """
        cutoff_time = datetime.utcnow() - timedelta(minutes=minutes)
        
        statement = select(NodeMetrics).where(
            NodeMetrics.node_id == node_id,
            NodeMetrics.recorded_at >= cutoff_time
        ).order_by(NodeMetrics.recorded_at.desc())
        
        metrics = session.exec(statement).all()
        return list(metrics)
    
    def calculate_node_score(
        self,
        node: Node,
        metrics: List[NodeMetrics]
    ) -> float:
        """
        è®¡ç®—èŠ‚ç‚¹çš„ AI è¯„åˆ†
        
        è¯„åˆ†å…¬å¼ï¼š
        - å»¶è¿Ÿå¾—åˆ† (40%): å»¶è¿Ÿè¶Šä½åˆ†è¶Šé«˜
        - è´Ÿè½½å¾—åˆ† (30%): è´Ÿè½½è¶Šä½åˆ†è¶Šé«˜
        - ç¨³å®šæ€§å¾—åˆ† (30%): ä¸¢åŒ…ç‡è¶Šä½åˆ†è¶Šé«˜
        - æ™šé«˜å³°æƒ©ç½š: -20 åˆ†
        
        Args:
            node: èŠ‚ç‚¹å¯¹è±¡
            metrics: ç›‘æ§æ•°æ®åˆ—è¡¨
        
        Returns:
            AI è¯„åˆ† (0-100)
        """
        # 1. å»¶è¿Ÿå¾—åˆ† (40%)
        latency_score = self.calculate_latency_score(metrics)
        
        # 2. è´Ÿè½½å¾—åˆ† (30%)
        load_score = self.calculate_load_score(node, metrics)
        
        # 3. ç¨³å®šæ€§å¾—åˆ† (30%)
        stability_score = self.calculate_stability_score(metrics)
        
        # 4. åŠ æƒæ€»åˆ†
        total_score = (
            latency_score * 0.4 +
            load_score * 0.3 +
            stability_score * 0.3
        )
        
        # 5. æ™šé«˜å³°æƒ©ç½š
        if self.is_peak_hour_congestion(metrics):
            logger.debug(f"  ğŸ• {node.name} æ£€æµ‹åˆ°æ™šé«˜å³°æ‹¥å µï¼Œæ‰£å‡ 20 åˆ†")
            total_score -= 20
        
        # 6. ç¡®ä¿åˆ†æ•°åœ¨ 0-100 ä¹‹é—´
        total_score = max(0, min(100, total_score))
        
        return round(total_score, 2)
    
    def calculate_latency_score(self, metrics: List[NodeMetrics]) -> float:
        """
        è®¡ç®—å»¶è¿Ÿå¾—åˆ†
        
        å…¬å¼: score = 100 / (avg_latency + 1)
        
        Args:
            metrics: ç›‘æ§æ•°æ®åˆ—è¡¨
        
        Returns:
            å»¶è¿Ÿå¾—åˆ† (0-100)
        """
        if not metrics:
            return 0
        
        # æå–æ‰€æœ‰å»¶è¿Ÿå€¼
        latencies = [m.latency for m in metrics if m.latency is not None]
        
        if not latencies:
            return 0
        
        # è®¡ç®—å¹³å‡å»¶è¿Ÿ
        avg_latency = mean(latencies)
        
        # è®¡ç®—å¾—åˆ†ï¼ˆå»¶è¿Ÿè¶Šä½åˆ†è¶Šé«˜ï¼‰
        score = 100 / (avg_latency + 1)
        
        # å½’ä¸€åŒ–åˆ° 0-100
        score = min(100, score * 10)  # æ”¾å¤§ç³»æ•°ï¼Œè®©ä½å»¶è¿Ÿæ›´æ˜æ˜¾
        
        return score
    
    def calculate_load_score(
        self,
        node: Node,
        metrics: List[NodeMetrics]
    ) -> float:
        """
        è®¡ç®—è´Ÿè½½å¾—åˆ†
        
        å…¬å¼: score = 100 - (load_factor * 100)
        
        Args:
            node: èŠ‚ç‚¹å¯¹è±¡
            metrics: ç›‘æ§æ•°æ®åˆ—è¡¨
        
        Returns:
            è´Ÿè½½å¾—åˆ† (0-100)
        """
        # ä½¿ç”¨èŠ‚ç‚¹å½“å‰çš„è´Ÿè½½ç³»æ•°
        load_factor = node.load_factor
        
        # å¦‚æœæœ‰ CPU ä½¿ç”¨ç‡æ•°æ®ï¼Œä¹Ÿè€ƒè™‘è¿›æ¥
        # TODO: ä» metrics ä¸­æå– CPU ä½¿ç”¨ç‡
        # ç›®å‰ç®€åŒ–å¤„ç†ï¼Œåªç”¨ load_factor
        
        score = 100 - (load_factor * 100)
        
        return max(0, score)
    
    def calculate_stability_score(self, metrics: List[NodeMetrics]) -> float:
        """
        è®¡ç®—ç¨³å®šæ€§å¾—åˆ†
        
        åŸºäºä¸¢åŒ…ç‡è®¡ç®—
        
        Args:
            metrics: ç›‘æ§æ•°æ®åˆ—è¡¨
        
        Returns:
            ç¨³å®šæ€§å¾—åˆ† (0-100)
        """
        if not metrics:
            return 0
        
        # æå–ä¸¢åŒ…ç‡
        packet_losses = [
            m.packet_loss for m in metrics
            if m.packet_loss is not None
        ]
        
        if not packet_losses:
            # å¦‚æœæ²¡æœ‰ä¸¢åŒ…ç‡æ•°æ®ï¼Œé»˜è®¤ç»™ 80 åˆ†
            return 80
        
        # è®¡ç®—å¹³å‡ä¸¢åŒ…ç‡
        avg_packet_loss = mean(packet_losses)
        
        # è®¡ç®—å¾—åˆ†ï¼ˆä¸¢åŒ…ç‡è¶Šä½åˆ†è¶Šé«˜ï¼‰
        # å‡è®¾ä¸¢åŒ…ç‡æ˜¯ 0-1 çš„æ¯”ä¾‹
        score = (1 - avg_packet_loss) * 100
        
        return max(0, score)
    
    def is_peak_hour_congestion(self, metrics: List[NodeMetrics]) -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºæ™šé«˜å³°æ‹¥å µæ—¶æ®µ
        
        åˆ¤æ–­é€»è¾‘ï¼š
        1. å½“å‰æ—¶é—´æ˜¯å¦ä¸ºæ™šé«˜å³° (18:00-23:00)
        2. æœ€è¿‘çš„å»¶è¿Ÿæ˜¯å¦æ˜¾è‘—é«˜äºå¹³å‡å€¼
        
        Args:
            metrics: ç›‘æ§æ•°æ®åˆ—è¡¨
        
        Returns:
            æ˜¯å¦ä¸ºæ™šé«˜å³°æ‹¥å µ
        """
        # 1. æ£€æŸ¥å½“å‰æ—¶é—´
        current_hour = datetime.now().hour
        is_peak_time = 18 <= current_hour <= 23
        
        if not is_peak_time:
            return False
        
        # 2. æ£€æŸ¥å»¶è¿Ÿæ˜¯å¦å¼‚å¸¸é«˜
        if len(metrics) < 10:
            return False
        
        latencies = [m.latency for m in metrics if m.latency is not None]
        
        if len(latencies) < 10:
            return False
        
        # æœ€è¿‘ 3 ä¸ªçš„å¹³å‡å»¶è¿Ÿ
        recent_latencies = latencies[:3]
        recent_avg = mean(recent_latencies)
        
        # å†å²å¹³å‡å»¶è¿Ÿ
        historical_avg = mean(latencies)
        
        # å¦‚æœæœ€è¿‘å»¶è¿Ÿæ¯”å†å²å¹³å‡é«˜ 50% ä»¥ä¸Šï¼Œè®¤ä¸ºæ‹¥å µ
        if recent_avg > historical_avg * 1.5:
            return True
        
        return False


# ==================== å…¨å±€å®ä¾‹ ====================

# åˆ›å»ºå…¨å±€è°ƒåº¦æœåŠ¡å®ä¾‹
scheduler_service = AISchedulerService(interval_seconds=60)


# ==================== ä¾¿æ·å‡½æ•° ====================

def start_scheduler():
    """å¯åŠ¨ AI è°ƒåº¦æœåŠ¡"""
    scheduler_service.start()


def stop_scheduler():
    """åœæ­¢ AI è°ƒåº¦æœåŠ¡"""
    scheduler_service.stop()


def update_scores_now():
    """ç«‹å³æ›´æ–°æ‰€æœ‰èŠ‚ç‚¹è¯„åˆ†ï¼ˆæ‰‹åŠ¨è§¦å‘ï¼‰"""
    scheduler_service.update_all_nodes_scores()
